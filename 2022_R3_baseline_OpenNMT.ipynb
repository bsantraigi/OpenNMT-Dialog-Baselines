{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qDWM5EliNvia",
    "outputId": "8b63227c-255c-460c-b285-750694b46c6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May  3 15:35:14 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   54C    P0    37W / 250W |   7701MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE...  Off  | 00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    27W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     48390      C   python                           7699MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mkxw_-BXTCMo",
    "outputId": "a564fc4e-611a-479e-ccbc-e3ca26646277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting OpenNMT-py\n",
      "  Downloading OpenNMT_py-2.2.0-py3-none-any.whl (216 kB)\n",
      "\u001b[K     |████████████████████████████████| 216 kB 552 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchtext==0.5.0\n",
      "  Downloading torchtext-0.5.0-py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 516 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting flask\n",
      "  Downloading Flask-2.1.2-py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 3.9 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /home/bishal/miniconda3/lib/python3.7/site-packages (from OpenNMT-py) (5.3.1)\n",
      "Collecting pyonmttok<2,>=1.23; platform_system == \"Linux\" or platform_system == \"Darwin\"\n",
      "  Downloading pyonmttok-1.31.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (16.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.6 MB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting configargparse\n",
      "  Downloading ConfigArgParse-1.5.3-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/bishal/miniconda3/lib/python3.7/site-packages (from OpenNMT-py) (1.10.2)\n",
      "Collecting tensorboard>=2.3\n",
      "  Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 791 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting waitress\n",
      "  Downloading waitress-2.1.1-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/bishal/miniconda3/lib/python3.7/site-packages (from torchtext==0.5.0->OpenNMT-py) (4.46.1)\n",
      "Requirement already satisfied: numpy in /home/bishal/miniconda3/lib/python3.7/site-packages (from torchtext==0.5.0->OpenNMT-py) (1.19.1)\n",
      "Requirement already satisfied: requests in /home/bishal/miniconda3/lib/python3.7/site-packages (from torchtext==0.5.0->OpenNMT-py) (2.24.0)\n",
      "Requirement already satisfied: sentencepiece in /home/bishal/miniconda3/lib/python3.7/site-packages (from torchtext==0.5.0->OpenNMT-py) (0.1.91)\n",
      "Requirement already satisfied: six in /home/bishal/miniconda3/lib/python3.7/site-packages (from torchtext==0.5.0->OpenNMT-py) (1.15.0)\n",
      "Collecting Werkzeug>=2.0\n",
      "  Downloading Werkzeug-2.1.2-py3-none-any.whl (224 kB)\n",
      "\u001b[K     |████████████████████████████████| 224 kB 840 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting click>=8.0\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 947 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Jinja2>=3.0\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 882 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-metadata>=3.6.0; python_version < \"3.10\"\n",
      "  Downloading importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: typing-extensions in /home/bishal/miniconda3/lib/python3.7/site-packages (from torch>=1.6.0->OpenNMT-py) (3.7.4.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/bishal/miniconda3/lib/python3.7/site-packages (from tensorboard>=2.3->OpenNMT-py) (0.4.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/bishal/miniconda3/lib/python3.7/site-packages (from tensorboard>=2.3->OpenNMT-py) (1.30.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/bishal/miniconda3/lib/python3.7/site-packages (from tensorboard>=2.3->OpenNMT-py) (1.19.2)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 952 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/bishal/miniconda3/lib/python3.7/site-packages (from tensorboard>=2.3->OpenNMT-py) (1.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/bishal/miniconda3/lib/python3.7/site-packages (from tensorboard>=2.3->OpenNMT-py) (3.2.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/bishal/miniconda3/lib/python3.7/site-packages (from tensorboard>=2.3->OpenNMT-py) (59.5.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/bishal/miniconda3/lib/python3.7/site-packages (from tensorboard>=2.3->OpenNMT-py) (0.34.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/bishal/miniconda3/lib/python3.7/site-packages (from tensorboard>=2.3->OpenNMT-py) (3.12.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/bishal/miniconda3/lib/python3.7/site-packages (from tensorboard>=2.3->OpenNMT-py) (0.9.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/bishal/miniconda3/lib/python3.7/site-packages (from requests->torchtext==0.5.0->OpenNMT-py) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/bishal/miniconda3/lib/python3.7/site-packages (from requests->torchtext==0.5.0->OpenNMT-py) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bishal/miniconda3/lib/python3.7/site-packages (from requests->torchtext==0.5.0->OpenNMT-py) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/bishal/miniconda3/lib/python3.7/site-packages (from requests->torchtext==0.5.0->OpenNMT-py) (1.25.10)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/bishal/miniconda3/lib/python3.7/site-packages (from importlib-metadata>=3.6.0; python_version < \"3.10\"->flask->OpenNMT-py) (3.1.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/bishal/miniconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.3->OpenNMT-py) (1.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/bishal/miniconda3/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/bishal/miniconda3/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /home/bishal/miniconda3/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (4.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/bishal/miniconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.3->OpenNMT-py) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/bishal/miniconda3/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.4.8)\n",
      "Installing collected packages: torchtext, Werkzeug, itsdangerous, importlib-metadata, click, MarkupSafe, Jinja2, flask, pyonmttok, configargparse, tensorboard-data-server, tensorboard, waitress, OpenNMT-py\n",
      "  Attempting uninstall: torchtext\n",
      "    Found existing installation: torchtext 0.6.0\n",
      "    Uninstalling torchtext-0.6.0:\n",
      "      Successfully uninstalled torchtext-0.6.0\n",
      "  Attempting uninstall: Werkzeug\n",
      "    Found existing installation: Werkzeug 1.0.1\n",
      "    Uninstalling Werkzeug-1.0.1:\n",
      "      Successfully uninstalled Werkzeug-1.0.1\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 1.7.0\n",
      "    Uninstalling importlib-metadata-1.7.0:\n",
      "      Successfully uninstalled importlib-metadata-1.7.0\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 7.1.2\n",
      "    Uninstalling click-7.1.2:\n",
      "      Successfully uninstalled click-7.1.2\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 1.1.1\n",
      "    Uninstalling MarkupSafe-1.1.1:\n",
      "      Successfully uninstalled MarkupSafe-1.1.1\n",
      "  Attempting uninstall: Jinja2\n",
      "    Found existing installation: Jinja2 2.11.2\n",
      "    Uninstalling Jinja2-2.11.2:\n",
      "      Successfully uninstalled Jinja2-2.11.2\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.2.2\n",
      "    Uninstalling tensorboard-2.2.2:\n",
      "      Successfully uninstalled tensorboard-2.2.2\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tensorflow 2.2.0 requires scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.5.0 which is incompatible.\n",
      "tensorflow 2.2.0 requires tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 2.9.0 which is incompatible.\n",
      "huggingface-hub 0.4.0 requires packaging>=20.9, but you'll have packaging 20.4 which is incompatible.\n",
      "datasets 1.10.2 requires huggingface-hub<0.1.0, but you'll have huggingface-hub 0.4.0 which is incompatible.\u001b[0m\n",
      "Successfully installed Jinja2-3.1.2 MarkupSafe-2.1.1 OpenNMT-py-2.2.0 Werkzeug-2.1.2 click-8.1.3 configargparse-1.5.3 flask-2.1.2 importlib-metadata-4.11.3 itsdangerous-2.1.2 pyonmttok-1.31.0 tensorboard-2.9.0 tensorboard-data-server-0.6.1 torchtext-0.5.0 waitress-2.1.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install git+https://github.com/OpenNMT/OpenNMT-py.git\n",
    "!pip install OpenNMT-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x-0BVzEbU3z4",
    "outputId": "e68b3706-c1bb-4482-f101-ed70933540d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '2022-R3-Mirror-Baseline'...\n",
      "remote: Enumerating objects: 118, done.\u001b[K\n",
      "remote: Counting objects: 100% (118/118), done.\u001b[K\n",
      "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
      "remote: Total 118 (delta 38), reused 109 (delta 29), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (118/118), 15.10 MiB | 8.11 MiB/s, done.\n",
      "Resolving deltas: 100% (38/38), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://bsantraigi:@github.com/bsantraigi/2022-R3-Mirror-Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ix1cwZioWLqI",
    "outputId": "2cd397bb-ad08-4c1d-e74f-f53204acde65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bishal/HULK/Projects/2022-r3-opennmt-dialog/2022-R3-Mirror-Baseline\n"
     ]
    }
   ],
   "source": [
    "%cd 2022-R3-Mirror-Baseline/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "snAFfHOfVgqs",
    "outputId": "eb119a33-b3cb-4ec0-e8eb-1a152815ab46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ijcnlp_dailydialog.zip\n",
      "   creating: data/ijcnlp_dailydialog/\n",
      "  inflating: data/ijcnlp_dailydialog/.DS_Store  \n",
      "  inflating: data/ijcnlp_dailydialog/dialogues_act.txt  \n",
      "  inflating: data/ijcnlp_dailydialog/dialogues_emotion.txt  \n",
      "  inflating: data/ijcnlp_dailydialog/dialogues_text.txt  \n",
      "  inflating: data/ijcnlp_dailydialog/dialogues_topic.txt  \n",
      "  inflating: data/ijcnlp_dailydialog/readme.txt  \n",
      "  inflating: data/ijcnlp_dailydialog/test.zip  \n",
      " extracting: data/ijcnlp_dailydialog/train.zip  \n",
      "  inflating: data/ijcnlp_dailydialog/validation.zip  \n",
      "Archive:  data/ijcnlp_dailydialog/test.zip\n",
      "   creating: data/ijcnlp_dailydialog/test/\n",
      "  inflating: data/ijcnlp_dailydialog/test/dialogues_act_test.txt  \n",
      "  inflating: data/ijcnlp_dailydialog/test/dialogues_emotion_test.txt  \n",
      "  inflating: data/ijcnlp_dailydialog/test/dialogues_test.txt  \n",
      "Archive:  data/ijcnlp_dailydialog/train.zip\n",
      "   creating: data/ijcnlp_dailydialog/train/\n",
      "  inflating: data/ijcnlp_dailydialog/train/dialogues_act_train.txt  \n",
      "  inflating: data/ijcnlp_dailydialog/train/dialogues_emotion_train.txt  \n",
      "  inflating: data/ijcnlp_dailydialog/train/dialogues_train.txt  \n",
      "Archive:  data/ijcnlp_dailydialog/validation.zip\n",
      "   creating: data/ijcnlp_dailydialog/validation/\n",
      "  inflating: data/ijcnlp_dailydialog/validation/dialogues_act_validation.txt  \n",
      "  inflating: data/ijcnlp_dailydialog/validation/dialogues_emotion_validation.txt  \n",
      "  inflating: data/ijcnlp_dailydialog/validation/dialogues_validation.txt  \n",
      "Processed train\n",
      "Processed validation\n",
      "Processed test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11118/11118 [00:00<00:00, 146736.96it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 140606.91it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 163680.16it/s]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wget -q -c http://yanran.li/files/ijcnlp_dailydialog.zip\n",
    "unzip ijcnlp_dailydialog.zip -d data/\n",
    "rm ijcnlp_dailydialog.zip\n",
    "\n",
    "unzip data/ijcnlp_dailydialog/test.zip -d data/ijcnlp_dailydialog/\n",
    "unzip data/ijcnlp_dailydialog/train.zip -d data/ijcnlp_dailydialog/\n",
    "unzip data/ijcnlp_dailydialog/validation.zip -d data/ijcnlp_dailydialog/\n",
    "\n",
    "python preprocess_dd.py\n",
    "# python -u preprocess.py \\\n",
    "#   -train_src data/ijcnlp_dailydialog/train.src.txt \\\n",
    "#   -train_tgt data/ijcnlp_dailydialog/train.tgt.txt \\\n",
    "#   -train_ctx data/ijcnlp_dailydialog/train.ctx.txt \\\n",
    "#   -valid_src data/ijcnlp_dailydialog/validation.src.txt \\\n",
    "#   -valid_tgt data/ijcnlp_dailydialog/validation.tgt.txt \\\n",
    "#   -valid_ctx data/ijcnlp_dailydialog/validation.ctx.txt \\\n",
    "#   -save_data data/ijcnlp_dailydialog/pair_daily -dynamic_dict -share_vocab \\\n",
    "#   -src_seq_length 45 -ctx_seq_length 100 -tgt_seq_length 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GtMXvD2jJgtI"
   },
   "outputs": [],
   "source": [
    "!mkdir -p configs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2h6kZDWYWPs0",
    "outputId": "44f78b9b-2773-4a0f-ddf7-51581ac15c4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing configs/dd_data.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile configs/dd_data.yaml\n",
    "# toy_en_de.yaml\n",
    "\n",
    "## Where the samples will be written\n",
    "save_data: data/ijcnlp_dailydialog/run/\n",
    "\n",
    "## Where the vocab(s) will be written\n",
    "src_vocab: data/ijcnlp_dailydialog/run/vocab.src\n",
    "tgt_vocab: data/ijcnlp_dailydialog/run/vocab.tgt\n",
    "\n",
    "# Prevent overwriting existing files in the folder\n",
    "overwrite: False\n",
    "\n",
    "# Corpus opts:\n",
    "data:\n",
    "    corpus_1:\n",
    "        path_src: data/ijcnlp_dailydialog/train.src.txt\n",
    "        path_tgt: data/ijcnlp_dailydialog/train.tgt.txt\n",
    "    valid:\n",
    "        path_src: data/ijcnlp_dailydialog/validation.src.txt\n",
    "        path_tgt: data/ijcnlp_dailydialog/validation.tgt.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41ONOCxdJeVq",
    "outputId": "16ff0586-5648-499d-d24c-4c244fa36616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
      "[2022-05-02 21:19:52,766 INFO] Counter vocab from 1000000 samples.\n",
      "[2022-05-02 21:19:52,766 INFO] Build vocab on 1000000 transformed examples/corpus.\n",
      "[2022-05-02 21:19:52,785 INFO] corpus_1's transforms: TransformPipe()\n",
      "[2022-05-02 21:19:53,591 INFO] Counters src:22431\n",
      "[2022-05-02 21:19:53,591 INFO] Counters tgt:22088\n"
     ]
    }
   ],
   "source": [
    "!onmt_build_vocab -config configs/dd_data.yaml -n_sample 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Qcz0rBkK7fW",
    "outputId": "9eeeb151-636e-4c82-dde6-709829cba151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting configs/dd_transformer_wordvocab_model.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile configs/dd_transformer_wordvocab_model.yaml\n",
    "## Where the samples will be written\n",
    "save_data: data/ijcnlp_dailydialog/run/\n",
    "\n",
    "## Where the vocab(s) will be written\n",
    "src_vocab: data/ijcnlp_dailydialog/run/vocab.src\n",
    "tgt_vocab: data/ijcnlp_dailydialog/run/vocab.tgt\n",
    "\n",
    "# Prevent overwriting existing files in the folder\n",
    "overwrite: False\n",
    "\n",
    "# Corpus opts:\n",
    "data:\n",
    "    corpus_1:\n",
    "        path_src: data/ijcnlp_dailydialog/train.src.txt\n",
    "        path_tgt: data/ijcnlp_dailydialog/train.tgt.txt\n",
    "    valid:\n",
    "        path_src: data/ijcnlp_dailydialog/validation.src.txt\n",
    "        path_tgt: data/ijcnlp_dailydialog/validation.tgt.txt\n",
    "\n",
    "# ----------------------------\n",
    "# data: data/ijcnlp_dailydialog/run/\n",
    "\n",
    "# Vocabulary files that were just created\n",
    "src_vocab: data/ijcnlp_dailydialog/run/vocab.src\n",
    "tgt_vocab: data/ijcnlp_dailydialog/run/vocab.tgt\n",
    "\n",
    "save_model: data/ijcnlp_dailydialog/run/transformer_wordvocab\n",
    "save_checkpoint_steps: 10000\n",
    "keep_checkpoint: 10\n",
    "seed: 3435\n",
    "train_steps: 500000\n",
    "valid_steps: 10000\n",
    "warmup_steps: 8000\n",
    "report_every: 100\n",
    "\n",
    "decoder_type: transformer\n",
    "encoder_type: transformer\n",
    "word_vec_size: 512\n",
    "rnn_size: 512\n",
    "layers: 6\n",
    "transformer_ff: 2048\n",
    "heads: 8\n",
    "\n",
    "accum_count: 8\n",
    "optim: adam\n",
    "adam_beta1: 0.9\n",
    "adam_beta2: 0.998\n",
    "decay_method: noam\n",
    "learning_rate: 2.0\n",
    "max_grad_norm: 0.0\n",
    "\n",
    "batch_size: 8192\n",
    "batch_type: tokens\n",
    "normalization: tokens\n",
    "dropout: 0.1\n",
    "label_smoothing: 0.1\n",
    "\n",
    "max_generator_batches: 2\n",
    "\n",
    "param_init: 0.0\n",
    "param_init_glorot: 'true'\n",
    "position_encoding: 'true'\n",
    "\n",
    "world_size: 1\n",
    "gpu_ranks:\n",
    "- 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5BotWALKDKH",
    "outputId": "88eed01c-0dc1-486e-f2ec-0bbb5130d46a"
   },
   "outputs": [],
   "source": [
    "!onmt_train -config configs/dd_transformer_wordvocab_model.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0gTFgGU8Mqy6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2022-R3-baseline-OpenNMT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
